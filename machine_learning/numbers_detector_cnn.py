# -*- coding: utf-8 -*-
"""numbers-detector-cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19yD
"""

!pip install mnist

import numpy as np
import mnist
import tensorflow as tf
from tensorflow import keras
from matplotlib import pyplot


tf.__version__
#np.__version__ # 1.21.6

#  Manual convolution and Pooling implentations

class Conv3x3:
  # A Convolution layer using 3x3 filters.

  def __init__(self, num_filters):
    self.num_filters = num_filters

    # filters is a 3d array with dimensions (num_filters, 3, 3)
    # We divide by 9 to reduce the variance of our initial values
    self.filters = np.random.randn(num_filters, 3, 3) / 9
    
    #sobel_filter = np.array([[-1, 0, 1], [-2, 0, -2], [-1, 0, 1]])
    #self.filters = np.array([sobel_filter])
    #self.num_filters = 1


  def iterate_regions(self, image):
    '''
    Generates all possible 3x3 image regions using valid padding.
    - image is a 2d numpy array
    '''
    h, w = image.shape

    for i in range(h - 2):
      for j in range(w - 2):
        im_region = image[i:(i + 3), j:(j + 3)]
        yield im_region, i, j

  def forward(self, input):
    '''
    Performs a forward pass of the conv layer using the given input.
    Returns a 3d numpy array with dimensions (h, w, num_filters).
    - input is a 2d numpy array
    '''
    h, w = input.shape
    output = np.zeros((h - 2, w - 2, self.num_filters))

    for im_region, i, j in self.iterate_regions(input):
      output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))

    return output


class MaxPool2:
  # A Max Pooling layer using a pool size of 2.

  def iterate_regions(self, image):
    '''
    Generates non-overlapping 2x2 image regions to pool over.
    - image is a 2d numpy array
    '''
    h, w, _ = image.shape
    new_h = h // 2
    new_w = w // 2

    for i in range(new_h):
      for j in range(new_w):
        im_region = image[(i * 2):(i * 2 + 2), (j * 2):(j * 2 + 2)]
        yield im_region, i, j

  def forward(self, input):
    '''
    Performs a forward pass of the maxpool layer using the given input.
    Returns a 3d numpy array with dimensions (h / 2, w / 2, num_filters).
    - input is a 3d numpy array with dimensions (h, w, num_filters)
    '''
    h, w, num_filters = input.shape
    output = np.zeros((h // 2, w // 2, num_filters))

    for im_region, i, j in self.iterate_regions(input):
      output[i, j] = np.amax(im_region, axis=(0, 1))

    return output

# Image helper

from PIL import Image

def save_image(output, name):
  img = Image.fromarray(output, 'RGB')
  img.save(name)
  img.show()
  return img



def plot_image(numpy_2d_array):
  pyplot.subplot(330 + 1)
  pyplot.imshow(numpy_2d_array, cmap=pyplot.get_cmap('gray'))
  pyplot.show()

train_images = mnist.train_images()


# show image from MNIST
#print(train_images[i].shape)
#for i in range(9):  
#  pyplot.subplot(330 + 1 + i)
#  pyplot.imshow(train_images[i], cmap=pyplot.get_cmap('gray'))
#  pyplot.show()


image_1 = train_images[0]
pyplot.subplot(330 + 1)
pyplot.imshow(image_1, cmap=pyplot.get_cmap('gray'))
pyplot.show()


# apply filters to image_1
conv = Conv3x3(8)
pool = MaxPool2()

output = conv.forward(image_1)
output = pool.forward(output)
print(output.shape)

# when there's only one filter instead of 8, transform single element vector into just the element
#new_shape = np.squeeze(output)   26x26 instead of 26x26x1


# print all the filtered images (8) for a given image_1
for pic_filter_index in range(8):
  M = []
  for i in range(13):
    A = []
    for j in range(13):
      A.append(output[i][j][pic_filter_index])
    M.append(A)

  new_shape = np.array(M)

  print(new_shape.shape)
  pyplot.subplot(330 + 1)
  pyplot.imshow(new_shape, cmap=pyplot.get_cmap('gray'))
  pyplot.show()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten
from tensorflow.keras.utils import to_categorical

train_images = mnist.train_images()
train_labels = mnist.train_labels()
test_images = mnist.test_images()
test_labels = mnist.test_labels()

# Normalize the images.
train_images = (train_images / 255) - 0.5
test_images = (test_images / 255) - 0.5

# Reshape the images.
train_images = np.expand_dims(train_images, axis=3)
test_images = np.expand_dims(test_images, axis=3)

num_filters = 8
filter_size = 3
pool_size = 2

# Build the model.
model = Sequential([
  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),
  MaxPooling2D(pool_size=pool_size),
  Flatten(),
  Dense(10, activation='softmax'),
])

# Compile the model.
model.compile(
  'adam',
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)

# Train the model.
model.fit(
  train_images,
  to_categorical(train_labels),   # Keras expects the training targets to be 10-dimensional vectors, since there are 10 nodes in our Softmax output layer. This turns our array of class integers into an array of one-hot vectors instead. For example, 2 would become [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]
  epochs=3,
  validation_data=(test_images, to_categorical(test_labels)),
)

model.save_weights('cnn.h5')



"""#Another option of the same"""

import tensorflow as tf # tensorflow 2.0
from keras.datasets import mnist
import numpy as np
seed=0
np.random.seed(seed) # fix random seed
tf.random.set_seed(seed)
# input image dimensions
num_classes = 10 # 10 digits
img_rows, img_cols = 28, 28 # number of pixels
# the data, shuffled and split between train and test sets
(X_train, Y_train), (X_test, Y_test) = mnist.load_data()
X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1) 
X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)
input_shape = (img_rows, img_cols, 1)
# cast floats to single precision
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
# rescale data in interval [0,1]
X_train /= 255
X_test /= 255
Y_train = keras.utils.to_categorical(Y_train, num_classes)
Y_test = keras.utils.to_categorical(Y_test, num_classes)

from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten 
from keras.layers import MaxPooling2D, Dropout
model_1 = Sequential()#add model layers
model_1.add(Conv2D(32, kernel_size=(5, 5),
                     activation='relu',
                     input_shape=input_shape))
model_1.add(MaxPooling2D(pool_size=(2, 2)))
# add second convolutional layer with 20 filters
model_1.add(Conv2D(64, (5, 5), activation='relu'))
    
# add 2D pooling layer
model_1.add(MaxPooling2D(pool_size=(2, 2)))
    
# flatten data
model_1.add(Flatten())

# add a dense all-to-all relu layer
model_1.add(Dense(1024, activation='relu'))
    
# apply dropout with rate 0.5
model_1.add(Dropout(0.5))
    
# soft-max layer
model_1.add(Dense(num_classes, activation='softmax'))


#compile model using accuracy to measure model performance
model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
#train the model
model_1.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=3)
# evaluate the model
score = model_1.evaluate(X_test, Y_test, verbose=1)
# print performance
print()
print('Test loss:', score[0])
print('Test accuracy:', score[1])

"""#Using and playing with the model"""

# lets use the model:
test_images_2 = mnist.test_images()
image_1 = test_images_2[0]
plot_image(image_1)


# Predict on the first 5 test images.
predictions = model.predict(test_images[:5])

# Print our model's predictions.
print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]

# Check our predictions against the ground truths.
print(test_labels[:5]) # [7, 2, 1, 0, 4]


# From second Tutorial
#predict first 4 images in the test set
#model.predict(X_test[:4])
#model.predict_classes(X_test[:4])
#actual results for first 4 images in test set
#Y_test[:4]

def decode_image(filename, image_type, resize_shape, channels):
    value = tf.io.read_file(filename)
    if image_type == 'png':
        decoded_image = tf.image.decode_png(value, channels=channels)
    elif image_type == 'jpeg':
        decoded_image = tf.image.decode_jpeg(value, channels=channels)
    else:
        decoded_image = tf.image.decode_image(value, channels=channels)
    
    if resize_shape is not None and image_type in ['png', 'jpeg']:
        decoded_image = tf.image.resize(decoded_image, resize_shape)
    
    return decoded_image  # results in an output shape of NHWC


def get_dataset(image_paths, image_type, resize_shape, channels):
    filename_tensor = tf.constant(image_paths)
    dataset = tf.data.Dataset.from_tensor_slices(filename_tensor)
    
    def _map_fn(filename):
        decode_images = decode_image(filename, image_type, resize_shape, channels=channels)
        return decode_images
    
    map_dataset = dataset.map(_map_fn) # we use the map method: allow to apply the function _map_fn to all the elements of dataset 
    return map_dataset


def get_image_data(image_paths, image_type, resize_shape, channels):
    dataset = get_dataset(image_paths, image_type, resize_shape, channels)
    iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)
    next_image = iterator.get_next()
    
    return next_image

from tensorflow.python import image
image_data = get_image_data(["gnum1.jpg"], "jpg", 0, 1)   # returns class 'tensorflow.python.framework.ops.EagerTensor'
#new_shape = np.squeeze(image_data)
#plot_image(new_shape)


#print(image_data.shape)
#print(type(test_images[0]))
#print(test_images.shape)  # (10000, 28, 28, 1)
#print(test_images[0].shape)   # (28, 28, 1)

#print(test_images_2[0])
#print(test_images[0])

image_data = (image_data / 255) - 0.5
my_list = np.array([image_data])

#my_images = np.expand_dims(my_list, axis=3)
#print(my_list.shape)

#print(image_data)

predictions = model.predict(my_list)
print(np.argmax(predictions, axis=1))
